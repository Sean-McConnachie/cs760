{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c1a28be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /home/dude-desktop/dev/cs760\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")  # go to project root\n",
    "print(f\"cwd: {os.getcwd()}\")  # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a11d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from diffusers import StableDiffusionInpaintPipeline\n",
    "# from PIL import Image\n",
    "\n",
    "# image = Image.open(\"outputs/debug_video_frame.png\").convert(\"RGB\")\n",
    "# mask_image = Image.open(\"outputs/debug_mask_frame.png\").convert(\"RGB\")\n",
    "\n",
    "\n",
    "# pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "#     \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "#     torch_dtype=torch.float16,\n",
    "# )\n",
    "# pipe.to(\"cuda\")\n",
    "# prompt = \"Face of a yellow cat, high resolution, sitting on a park bench\"\n",
    "# #image and mask_image should be PIL images.\n",
    "# #The mask structure is white for inpainting and black for keeping as is\n",
    "# image = pipe(prompt=prompt, image=image, mask_image=mask_image).images[0]\n",
    "# image.save(\"./yellow_cat_on_park_bench.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef05a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from lib import iter_dir_for_video_and_mask, get_video_stats, ensure_video_and_mask_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b88f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionInpaintPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f380a708ec424903be2aa1493c926616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "    dtype=torch.float16,\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16096e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 30.0, Width: 320, Height: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c66d0650aeb462685278ad6fcb02404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:42<00:42, 42.26s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae26853d2914cae88f143838713126f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:52<00:00, 26.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inpainted video saved to outputs/output_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def inpaint_video_borders(pipe, video_path, mask_path, output_path, prompt, batch_size=64, seed=42):\n",
    "    assert os.path.exists(video_path), f\"Video path {video_path} does not exist.\"\n",
    "    assert os.path.exists(mask_path), f\"Mask path {mask_path} does not exist\"\n",
    "    \n",
    "    # loading video and mask with opencv\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    mask_capture = cv2.VideoCapture(mask_path)\n",
    "\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f\"Video FPS: {fps}, Width: {width}, Height: {height}\")\n",
    "\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "    mask_frames = []\n",
    "    while True:\n",
    "        ret, frame = mask_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.bitwise_not(frame)\n",
    "        mask_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "        mask_frames.append(mask_frame)\n",
    "\n",
    "    video_capture.release()\n",
    "    mask_capture.release()\n",
    "\n",
    "    if len(frames) != len(mask_frames):\n",
    "        raise ValueError(\"The number of frames in the video and mask must be the same.\")\n",
    "    \n",
    "    generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "\n",
    "    output_frames = []\n",
    "    for i in tqdm(range(0, len(frames), batch_size), total=(len(frames) + batch_size - 1) // batch_size):\n",
    "        frame_batch = frames[i:i + batch_size]\n",
    "        mask_batch = mask_frames[i:i + batch_size]\n",
    "        prompts = [prompt] * len(frame_batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(\"cuda\"):\n",
    "                output = pipe(\n",
    "                    prompt=prompts,\n",
    "                    image=frame_batch,\n",
    "                    mask_image=mask_batch,\n",
    "                    width=width,\n",
    "                    height=height,\n",
    "                    generator=generator,\n",
    "                ).images\n",
    "\n",
    "        output_frames.extend(output)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # combine outputted frames back into video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for frame in output_frames:\n",
    "        if isinstance(frame, Image.Image):\n",
    "            frame = np.array(frame)\n",
    "        frame = frame.astype(np.uint8)\n",
    "        # Convert RGB (from PIL) to BGR (for OpenCV)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Inpainted video saved to {output_path}\")\n",
    "\n",
    "\n",
    "dummy_video_path = \"out_pairs/stabilised/_Boom_Snap_Clap__challenge_clap_u_nm_np1_fr_med_1.avi\"\n",
    "dummy_mask_path = \"out_pairs/masks/_Boom_Snap_Clap__challenge_clap_u_nm_np1_fr_med_1_mask.avi\"\n",
    "output_video_path = \"outputs/output_video.mp4\"\n",
    "inpaint_video_borders(\n",
    "    pipe=pipe,\n",
    "    video_path=dummy_video_path,\n",
    "    mask_path=dummy_mask_path,\n",
    "    output_path=output_video_path,\n",
    "    prompt=\"A realistic photo.\",\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e8ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking video and mask: 100%|██████████| 500/500 [00:00<00:00, 566.46it/s]\n",
      "Inpainting videos:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 30.0, Width: 320, Height: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ffb0672bcb414f84f23f60f49c840c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cc2cc4f9434e7193cd2f65b1ffc6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dir = \"out_pairs\"\n",
    "output_dir = \"outputs/StableDiffusion\"\n",
    "output_width, output_height = 320, 240\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for video in tqdm(iter_dir_for_video_and_mask(\n",
    "    input_dir, video_dir=\"stabilised\"\n",
    "), desc=\"Checking video and mask\"):\n",
    "    video_stats = get_video_stats(video[\"video\"])\n",
    "    mask_stats = get_video_stats(video[\"mask\"])\n",
    "    mask_stats.frame_count = video_stats.frame_count  # TODO: HACK\n",
    "    ensure_video_and_mask_match(video_stats, mask_stats)\n",
    "    assert video_stats.width == output_width\n",
    "    assert video_stats.height == output_height\n",
    "\n",
    "for video in tqdm(iter_dir_for_video_and_mask(\n",
    "    input_dir, video_dir=\"stabilised\"\n",
    "), desc=\"Inpainting videos\"):\n",
    "    video_name = os.path.basename(video[\"video\"])\n",
    "    output_path = os.path.join(output_dir, video_name)\n",
    "    inpaint_video_borders(\n",
    "        pipe=pipe,\n",
    "        video_path=video[\"video\"],\n",
    "        mask_path=video[\"mask\"],\n",
    "        output_path=output_path,\n",
    "        prompt=\"A realistic photo.\",\n",
    "        batch_size=32\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs760",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
